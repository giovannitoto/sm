{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link utili:\n",
    "\n",
    "- Homepage `twint`: https://github.com/twintproject/twint\n",
    "\n",
    "- Installazione della versione corretta della libreria `tornado`: https://stackoverflow.com/questions/53248431/asyncio-runtimeerror-this-event-loop-is-already-running\n",
    "\n",
    "- Campi di ricerca: https://github.com/twintproject/twint/wiki/Configuration\n",
    "\n",
    "- Formattazione: https://github.com/twintproject/twint/wiki/Tweet-attributes\n",
    "\n",
    "- `twint` e `Pandas`: https://github.com/twintproject/twint/wiki/Pandas-integration\n",
    "\n",
    "- Indexing and selecting data in `Pandas`: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html\n",
    "\n",
    "- Homepage `emoji`: https://pypi.org/project/emoji/\n",
    "\n",
    "- Lista completa emoji: http://www.unicode.org/emoji/charts/full-emoji-list.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from emoji import demojize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lista delle persone escluse:\n",
    "- [M5S] Beppe Grillo\n",
    "- [PD] Paola Boldrini (boldrini_paola) ha solo 21 tweet\n",
    "- [LSP] Erika Stefani (erikastefani71) ha solo 10 tweet\n",
    "- [PD] Walter Verini (VeriniWalter) non posta nulla dal 2018\n",
    "\n",
    "Persone da valutare:\n",
    "- [M5S] Stefano Patuanelli (SPatuanelli) ha solo 49 tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persone d'interesse\n",
    "MVP = {\"GiuseppeConteIT\": \"Giuseppe Conte\",\n",
    "       \"Fedez\": \"Fedez\"}\n",
    "# Movimento 5 Stelle\n",
    "M5S = {\"Mov5Stelle\": \"MoVimento 5 Stelle\",\n",
    "       \"luigidimaio\": \"Luigi di Maio\",\n",
    "       \"SPatuanelli\": \"Stefano Patuanelli\",\n",
    "       \"Roberto_Fico\": \"Roberto Fico\",\n",
    "       \"LauraBottici\": \"Laura Bottici\",\n",
    "       \"vitocrimi\": \"Vito Crimi\"}\n",
    "# Lega - Salvini Premier\n",
    "LSP = {\"LegaSalvini\": \"Lega - Salvini Premier\",\n",
    "       \"matteosalvinimi\": \"Matteo Salvini\",\n",
    "       \"MolinariRik\": \"Riccardo Molinari\",\n",
    "       \"FabriCecchetti\": \"Fabrizio Cecchetti\",\n",
    "       \"Fontana3Lorenzo\": \"Lorenzo Fontana\",\n",
    "       \"massimogara\": \"Massimo Garavaglia\"}\n",
    "# Partito Democratico\n",
    "PD = {\"pdnetwork\": \"Partito Democratico\",\n",
    "      \"EnricoLetta\": \"Enrico Letta\",\n",
    "      \"itinagli\": \"Irene Tinagli\",\n",
    "      \"peppeprovenzano\": \"Giuseppe Provenzano\",\n",
    "      \"F_Boccia\": \"Francesco Boccia\",\n",
    "      \"lauraboldrini\": \"Laura Boldrini\",\n",
    "      \"PaoloGentiloni\": \"Paolo Gentiloni\",\n",
    "      \"robersperanza\": \"Roberto Speranza\",\n",
    "      \"dariofrance\": \"Dario Franceschini\"}\n",
    "# Forza Italia\n",
    "FI = {\"forza_italia\": \"Forza Italia\",\n",
    "      \"berlusconi\": \"Silvio Berlusconi\",\n",
    "      \"Antonio_Tajani\": \"Antonio Tajani\",\n",
    "      \"msgelmini\": \"Mariastella Gelmini\",\n",
    "      \"mara_carfagna\": \"Mara Carfagna\",\n",
    "      \"renatobrunetta\": \"Renato Brunetta\",\n",
    "      \"gasparripdl\": \"Maurizio Gasparri\",\n",
    "      \"BerniniAM\": \"Anna Maria Bernini\"}\n",
    "# Fratelli d'Italia\n",
    "FdI = {\"FratellidItalia\": \"Fratelli d'Italia\",\n",
    "       \"GiorgiaMeloni\": \"Giorgia Meloni\",\n",
    "       \"Ignazio_LaRussa\": \"Ignazio La Russa\",\n",
    "       \"GuidoCrosetto\": \"Guido Crosetto\",\n",
    "       \"DSantanche\": \"Daniela Santanch√®\",\n",
    "       \"RaffaeleFitto\": \"Raffaele Fitto\"}\n",
    "# Italia Viva\n",
    "IV = {\"ItaliaViva\": \"Italia Viva\",\n",
    "      \"matteorenzi\": \"Matteo Renzi\",\n",
    "      \"meb\": \"Maria Elena Boschi\",\n",
    "      \"Ettore_Rosato\": \"Ettore Rosato\",\n",
    "      \"TeresaBellanova\": \"Teresa Bellanova\",\n",
    "      \"elenabonetti\": \"Elena Bonetti\",\n",
    "      \"davidefaraone\": \"Davide Faraone\"}\n",
    "\n",
    "partito_list = {\"MVP\": list(MVP.keys()),\n",
    "                \"M5S\": list(M5S.keys()),\n",
    "                \"LSP\": list(LSP.keys()),\n",
    "                \"PD\": list(PD.keys()),\n",
    "                \"FI\": list(FI.keys()),\n",
    "                \"FdI\": list(FdI.keys()),\n",
    "                \"IV\": list(IV.keys())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scarico da Twitter tutti i tweet degli utenti contenuti nella lista `username_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVP: ['GiuseppeConteIT', 'Fedez']\n",
      "[1/2] 2021-05-09 01:27:40\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 418 Tweets from @GiuseppeConteIT.\n",
      "[2/2] 2021-05-09 01:27:48\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 344 Tweets from @Fedez.\n",
      "\n",
      "M5S: ['Mov5Stelle', 'luigidimaio', 'SPatuanelli', 'Roberto_Fico', 'LauraBottici', 'vitocrimi']\n",
      "[1/6] 2021-05-09 01:27:54\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3008 Tweets from @Mov5Stelle.\n",
      "[2/6] 2021-05-09 01:28:38\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 751 Tweets from @luigidimaio.\n",
      "[3/6] 2021-05-09 01:28:49\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 51 Tweets from @SPatuanelli.\n",
      "[4/6] 2021-05-09 01:28:51\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 265 Tweets from @Roberto_Fico.\n",
      "[5/6] 2021-05-09 01:28:56\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 164 Tweets from @LauraBottici.\n",
      "[6/6] 2021-05-09 01:29:00\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 177 Tweets from @vitocrimi.\n",
      "\n",
      "LSP: ['LegaSalvini', 'matteosalvinimi', 'MolinariRik', 'FabriCecchetti', 'Fontana3Lorenzo', 'massimogara']\n",
      "[1/6] 2021-05-09 01:29:04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 40667 Tweets from @LegaSalvini.\n",
      "[2/6] 2021-05-09 01:37:42\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 10737 Tweets from @matteosalvinimi.\n",
      "[3/6] 2021-05-09 01:39:58\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 210 Tweets from @MolinariRik.\n",
      "[4/6] 2021-05-09 01:40:02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1151 Tweets from @FabriCecchetti.\n",
      "[5/6] 2021-05-09 01:40:18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1588 Tweets from @Fontana3Lorenzo.\n",
      "[6/6] 2021-05-09 01:40:40\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2009 Tweets from @massimogara.\n",
      "\n",
      "PD: ['pdnetwork', 'EnricoLetta', 'itinagli', 'VeriniWalter', 'peppeprovenzano', 'F_Boccia', 'lauraboldrini', 'PaoloGentiloni', 'robersperanza', 'dariofrance']\n",
      "[1/10] 2021-05-09 01:41:08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1378 Tweets from @pdnetwork.\n",
      "[2/10] 2021-05-09 01:41:29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1547 Tweets from @EnricoLetta.\n",
      "[3/10] 2021-05-09 01:41:55\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 552 Tweets from @itinagli.\n",
      "[4/10] 2021-05-09 01:42:04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 0 Tweets from @VeriniWalter.\n",
      "[5/10] 2021-05-09 01:42:05\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 345 Tweets from @peppeprovenzano.\n",
      "[6/10] 2021-05-09 01:42:11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 352 Tweets from @F_Boccia.\n",
      "[7/10] 2021-05-09 01:42:18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 497 Tweets from @lauraboldrini.\n",
      "[8/10] 2021-05-09 01:42:26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 499 Tweets from @PaoloGentiloni.\n",
      "[9/10] 2021-05-09 01:42:34\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 276 Tweets from @robersperanza.\n",
      "[10/10] 2021-05-09 01:42:39\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 140 Tweets from @dariofrance.\n",
      "\n",
      "FI: ['forza_italia', 'berlusconi', 'Antonio_Tajani', 'msgelmini', 'mara_carfagna', 'renatobrunetta', 'gasparripdl', 'BerniniAM']\n",
      "[1/8] 2021-05-09 01:42:43\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 838 Tweets from @forza_italia.\n",
      "[2/8] 2021-05-09 01:42:58\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1006 Tweets from @berlusconi.\n",
      "[3/8] 2021-05-09 01:43:15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1817 Tweets from @Antonio_Tajani.\n",
      "[4/8] 2021-05-09 01:43:43\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1204 Tweets from @msgelmini.\n",
      "[5/8] 2021-05-09 01:44:03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 858 Tweets from @mara_carfagna.\n",
      "[6/8] 2021-05-09 01:44:16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2291 Tweets from @renatobrunetta.\n",
      "[7/8] 2021-05-09 01:44:48\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2272 Tweets from @gasparripdl.\n",
      "[8/8] 2021-05-09 01:45:19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 730 Tweets from @BerniniAM.\n",
      "\n",
      "FdI: ['FratellidItalia', 'GiorgiaMeloni', 'Ignazio_LaRussa', 'GuidoCrosetto', 'DSantanche', 'RaffaeleFitto']\n",
      "[1/6] 2021-05-09 01:45:31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 5688 Tweets from @FratellidItalia.\n",
      "[2/6] 2021-05-09 01:46:48\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2141 Tweets from @GiorgiaMeloni.\n",
      "[3/6] 2021-05-09 01:47:18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 261 Tweets from @Ignazio_LaRussa.\n",
      "[4/6] 2021-05-09 01:47:23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 11742 Tweets from @GuidoCrosetto.\n",
      "[5/6] 2021-05-09 01:49:42\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 2083 Tweets from @DSantanche.\n",
      "[6/6] 2021-05-09 01:50:12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 900 Tweets from @RaffaeleFitto.\n",
      "\n",
      "IV: ['ItaliaViva', 'matteorenzi', 'meb', 'Ettore_Rosato', 'TeresaBellanova', 'elenabonetti', 'davidefaraone']\n",
      "[1/7] 2021-05-09 01:50:26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 4951 Tweets from @ItaliaViva.\n",
      "[2/7] 2021-05-09 01:51:28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1160 Tweets from @matteorenzi.\n",
      "[3/7] 2021-05-09 01:51:45\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 242 Tweets from @meb.\n",
      "[4/7] 2021-05-09 01:51:50\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1353 Tweets from @Ettore_Rosato.\n",
      "[5/7] 2021-05-09 01:52:12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1677 Tweets from @TeresaBellanova.\n",
      "[6/7] 2021-05-09 01:52:35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 887 Tweets from @elenabonetti.\n",
      "[7/7] 2021-05-09 01:52:49\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 403 Tweets from @davidefaraone.\n",
      "\n",
      "******************************\n",
      "  Start: 2021-05-09 01:27:40\n",
      "    End: 2021-05-09 01:52:57\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "tweets_df_list = {}\n",
    "\n",
    "for partito in partito_list:\n",
    "    username_list = partito_list[partito]\n",
    "    print(partito + \":\", username_list)\n",
    "    for i in range(len(username_list)):\n",
    "        user_name = username_list[i]\n",
    "        print(\"[\" + str(i+1) + \"/\" + str(len(username_list)) + \"]\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        try:\n",
    "            c = twint.Config()\n",
    "\n",
    "            c.Username = user_name\n",
    "            c.User_full = True\n",
    "            c.Since = \"2020-02-01\"\n",
    "            c.Until = \"2021-05-15\"\n",
    "\n",
    "            c.Lowercase = True # rende tutto minuscolo\n",
    "\n",
    "            c.Count = True     # stampo a video il numero di tweet trovati\n",
    "            c.Pandas = True\n",
    "            c.Hide_output = True \n",
    "\n",
    "            twint.run.Search(c)\n",
    "\n",
    "            tweets_df_list[user_name] = twint.storage.panda.Tweets_df\n",
    "            tweets_df_list[user_name][\"partito\"] = partito\n",
    "        except Exception as ex:\n",
    "            print(\"*\"*30)\n",
    "            print(str(ex))\n",
    "            print(\"*\"*30)\n",
    "    print(\"\")\n",
    "\n",
    "print(\"\" + \"*\"*30)\n",
    "print(\"  Start:\", start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"    End:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unisco i vari dataframe contenuti nella lista `tweet_df_list` in uno unico che andr√† a formare il *corpus*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GiuseppeConteIT      (418, 39)\n",
      "Fedez                (344, 39)\n",
      "Mov5Stelle          (3008, 39)\n",
      "luigidimaio          (751, 39)\n",
      "SPatuanelli           (51, 39)\n",
      "Roberto_Fico         (265, 39)\n",
      "LauraBottici         (164, 39)\n",
      "vitocrimi            (177, 39)\n",
      "LegaSalvini        (40667, 39)\n",
      "matteosalvinimi    (10737, 39)\n",
      "MolinariRik          (210, 39)\n",
      "FabriCecchetti      (1151, 39)\n",
      "Fontana3Lorenzo     (1588, 39)\n",
      "massimogara         (2009, 39)\n",
      "pdnetwork           (1378, 39)\n",
      "EnricoLetta         (1547, 39)\n",
      "itinagli             (552, 39)\n",
      "VeriniWalter            (0, 1)\n",
      "peppeprovenzano      (345, 39)\n",
      "F_Boccia             (352, 39)\n",
      "lauraboldrini        (497, 39)\n",
      "PaoloGentiloni       (499, 39)\n",
      "robersperanza        (276, 39)\n",
      "dariofrance          (140, 39)\n",
      "forza_italia         (838, 39)\n",
      "berlusconi          (1006, 39)\n",
      "Antonio_Tajani      (1817, 39)\n",
      "msgelmini           (1204, 39)\n",
      "mara_carfagna        (858, 39)\n",
      "renatobrunetta      (2291, 39)\n",
      "gasparripdl         (2272, 39)\n",
      "BerniniAM            (730, 39)\n",
      "FratellidItalia     (5688, 39)\n",
      "GiorgiaMeloni       (2141, 39)\n",
      "Ignazio_LaRussa      (261, 39)\n",
      "GuidoCrosetto      (11742, 39)\n",
      "DSantanche          (2083, 39)\n",
      "RaffaeleFitto        (900, 39)\n",
      "ItaliaViva          (4951, 39)\n",
      "matteorenzi         (1160, 39)\n",
      "meb                  (242, 39)\n",
      "Ettore_Rosato       (1353, 39)\n",
      "TeresaBellanova     (1677, 39)\n",
      "elenabonetti         (887, 39)\n",
      "davidefaraone        (403, 39)\n",
      "------------------------------\n",
      "                  (111630, 39)\n"
     ]
    }
   ],
   "source": [
    "for user_name in tweets_df_list:\n",
    "    print(user_name.ljust(16), str(tweets_df_list[user_name].shape).rjust(13))\n",
    "print(\"-\"*30)\n",
    "\n",
    "# creo un unico dataframe\n",
    "tweets = pd.concat(tweets_df_list.values())\n",
    "print(\"\".ljust(16), str(tweets.shape).rjust(13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partito</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [partito]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df_list[\"VeriniWalter\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esporto il dataset originale in formato *csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets.to_csv(\"data/tweets_original_\"+datetime.now().strftime(\"%Y_%m_%d\")+\".csv\", sep=\"\\t\", index=False, encoding='utf-8-sig', mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gestisco gli emoji convertendoli in stringhe di testo comprensibile. Come deliminatore si utilizza `(\" emote_\",\" \")` in modo da rendere le emoji facilmente distinguibili; gli spazi servono per essere sicuri di considerarle come una singola entit√†."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"tweet\"] = tweets[\"tweet\"].apply(lambda x: demojize(x, language=\"en\", delimiters=(\" emote_\",\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infine, esporto il dataset normalizzato in formato *csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv(\"data/00_tweets.csv\", sep=\"\\t\", index=False, encoding='utf-8-sig', mode=\"w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "twitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
