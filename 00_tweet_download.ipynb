{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link utili:\n",
    "\n",
    "- Homepage `twint`: https://github.com/twintproject/twint\n",
    "\n",
    "- Installazione della versione corretta della libreria `tornado`: https://stackoverflow.com/questions/53248431/asyncio-runtimeerror-this-event-loop-is-already-running\n",
    "\n",
    "- Campi di ricerca: https://github.com/twintproject/twint/wiki/Configuration\n",
    "\n",
    "- Formattazione: https://github.com/twintproject/twint/wiki/Tweet-attributes\n",
    "\n",
    "- `twint` e `Pandas`: https://github.com/twintproject/twint/wiki/Pandas-integration\n",
    "\n",
    "- Indexing and selecting data in `Pandas`: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html\n",
    "\n",
    "- Homepage `emoji`: https://pypi.org/project/emoji/\n",
    "\n",
    "- Lista completa emoji: http://www.unicode.org/emoji/charts/full-emoji-list.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from emoji import demojize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lista delle persone escluse:\n",
    "- [M5S] Beppe Grillo\n",
    "- [PD] Paola Boldrini (boldrini_paola) ha solo 21 tweet\n",
    "- [LSP] Lega - Salvini Premier (LegaSalvini) ha troppi tweet\n",
    "- [LSP] Erika Stefani (erikastefani71) ha solo 10 tweet\n",
    "- [PD] Walter Verini (VeriniWalter) non posta nulla dal 2018\n",
    "\n",
    "Persone rimosse per bilanciare il dataset:\n",
    "- [FdI] \"FratellidItalia\": \"Fratelli d'Italia\"\n",
    "- [M5S] \"SPatuanelli\": \"Stefano Patuanelli\"\n",
    "- [LSP] \"MolinariRik\": \"Riccardo Molinari\"\n",
    "- [LSP] \"FabriCecchetti\": \"Fabrizio Cecchetti\"\n",
    "- [FdI] \"Ignazio_LaRussa\": \"Ignazio La Russa\"\n",
    "- [FdI] \"RaffaeleFitto\": \"Raffaele Fitto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movimento 5 Stelle\n",
    "M5S = {\"Mov5Stelle\": \"MoVimento 5 Stelle\",\n",
    "       \"luigidimaio\": \"Luigi di Maio\",\n",
    "       \"Roberto_Fico\": \"Roberto Fico\",\n",
    "       \"LauraBottici\": \"Laura Bottici\",\n",
    "       \"vitocrimi\": \"Vito Crimi\",\n",
    "       \"virginiaraggi\": \"Virginia Raggi\"}\n",
    "# Lega - Salvini Premier\n",
    "LSP = {\"matteosalvinimi\": \"Matteo Salvini\",\n",
    "       \"Fontana3Lorenzo\": \"Lorenzo Fontana\",\n",
    "       \"massimogara\": \"Massimo Garavaglia\"}\n",
    "# Partito Democratico\n",
    "PD = {\"pdnetwork\": \"Partito Democratico\",\n",
    "      \"EnricoLetta\": \"Enrico Letta\",\n",
    "      \"itinagli\": \"Irene Tinagli\",\n",
    "      \"peppeprovenzano\": \"Giuseppe Provenzano\",\n",
    "      \"F_Boccia\": \"Francesco Boccia\",\n",
    "      \"lauraboldrini\": \"Laura Boldrini\",\n",
    "      \"PaoloGentiloni\": \"Paolo Gentiloni\",\n",
    "      \"robersperanza\": \"Roberto Speranza\",\n",
    "      \"dariofrance\": \"Dario Franceschini\",\n",
    "      \"nzingaretti\": \"Nicola Zingaretti\",\n",
    "      \"ZanAlessandro\": \"Alessandro Zan\"}\n",
    "# Forza Italia\n",
    "FI = {\"forza_italia\": \"Forza Italia\",\n",
    "      \"berlusconi\": \"Silvio Berlusconi\",\n",
    "      \"Antonio_Tajani\": \"Antonio Tajani\",\n",
    "      \"msgelmini\": \"Mariastella Gelmini\",\n",
    "      \"mara_carfagna\": \"Mara Carfagna\",\n",
    "      \"renatobrunetta\": \"Renato Brunetta\",\n",
    "      \"gasparripdl\": \"Maurizio Gasparri\",\n",
    "      \"BerniniAM\": \"Anna Maria Bernini\"}\n",
    "# Fratelli d'Italia\n",
    "FdI = {\"GiorgiaMeloni\": \"Giorgia Meloni\",\n",
    "       \"GuidoCrosetto\": \"Guido Crosetto\",\n",
    "       \"DSantanche\": \"Daniela Santanch√®\"}\n",
    "# Italia Viva\n",
    "IV = {\"ItaliaViva\": \"Italia Viva\",\n",
    "      \"matteorenzi\": \"Matteo Renzi\",\n",
    "      \"meb\": \"Maria Elena Boschi\",\n",
    "      \"Ettore_Rosato\": \"Ettore Rosato\",\n",
    "      \"TeresaBellanova\": \"Teresa Bellanova\",\n",
    "      \"elenabonetti\": \"Elena Bonetti\",\n",
    "      \"davidefaraone\": \"Davide Faraone\"}\n",
    "\n",
    "partito_list = {\"M5S\": list(M5S.keys()),\n",
    "                \"LSP\": list(LSP.keys()),\n",
    "                \"PD\": list(PD.keys()),\n",
    "                \"FI\": list(FI.keys()),\n",
    "                \"FdI\": list(FdI.keys()),\n",
    "                \"IV\": list(IV.keys())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scarico da Twitter tutti i tweet degli utenti contenuti nella lista `username_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M5S: ['Mov5Stelle', 'luigidimaio', 'Roberto_Fico', 'LauraBottici', 'vitocrimi', 'virginiaraggi']\n",
      "[1/6] 2021-05-25 10:53:46\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1807 Tweets from @Mov5Stelle.\n",
      "[2/6] 2021-05-25 10:54:08\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 436 Tweets from @luigidimaio.\n",
      "[3/6] 2021-05-25 10:54:13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 178 Tweets from @Roberto_Fico.\n",
      "[4/6] 2021-05-25 10:54:16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 93 Tweets from @LauraBottici.\n",
      "[5/6] 2021-05-25 10:54:18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 131 Tweets from @vitocrimi.\n",
      "[6/6] 2021-05-25 10:54:20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1018 Tweets from @virginiaraggi.\n",
      "\n",
      "LSP: ['matteosalvinimi', 'Fontana3Lorenzo', 'massimogara']\n",
      "[1/3] 2021-05-25 10:54:33\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 7328 Tweets from @matteosalvinimi.\n",
      "[2/3] 2021-05-25 10:55:50\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1067 Tweets from @Fontana3Lorenzo.\n",
      "[3/3] 2021-05-25 10:56:02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 975 Tweets from @massimogara.\n",
      "\n",
      "PD: ['pdnetwork', 'EnricoLetta', 'itinagli', 'peppeprovenzano', 'F_Boccia', 'lauraboldrini', 'PaoloGentiloni', 'robersperanza', 'dariofrance', 'nzingaretti', 'ZanAlessandro']\n",
      "[1/11] 2021-05-25 10:56:15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1185 Tweets from @pdnetwork.\n",
      "[2/11] 2021-05-25 10:56:30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1043 Tweets from @EnricoLetta.\n",
      "[3/11] 2021-05-25 10:56:45\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 405 Tweets from @itinagli.\n",
      "[4/11] 2021-05-25 10:56:50\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 278 Tweets from @peppeprovenzano.\n",
      "[5/11] 2021-05-25 10:56:55\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 150 Tweets from @F_Boccia.\n",
      "[6/11] 2021-05-25 10:56:58\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 420 Tweets from @lauraboldrini.\n",
      "[7/11] 2021-05-25 10:57:04\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 369 Tweets from @PaoloGentiloni.\n",
      "[8/11] 2021-05-25 10:57:09\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 181 Tweets from @robersperanza.\n",
      "[9/11] 2021-05-25 10:57:12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 85 Tweets from @dariofrance.\n",
      "[10/11] 2021-05-25 10:57:14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 485 Tweets from @nzingaretti.\n",
      "[11/11] 2021-05-25 10:57:20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 149 Tweets from @ZanAlessandro.\n",
      "\n",
      "FI: ['forza_italia', 'berlusconi', 'Antonio_Tajani', 'msgelmini', 'mara_carfagna', 'renatobrunetta', 'gasparripdl', 'BerniniAM']\n",
      "[1/8] 2021-05-25 10:57:23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 621 Tweets from @forza_italia.\n",
      "[2/8] 2021-05-25 10:57:30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 616 Tweets from @berlusconi.\n",
      "[3/8] 2021-05-25 10:57:37\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1240 Tweets from @Antonio_Tajani.\n",
      "[4/8] 2021-05-25 10:57:51\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 690 Tweets from @msgelmini.\n",
      "[5/8] 2021-05-25 10:58:00\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 542 Tweets from @mara_carfagna.\n",
      "[6/8] 2021-05-25 10:58:07\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1429 Tweets from @renatobrunetta.\n",
      "[7/8] 2021-05-25 10:58:24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1358 Tweets from @gasparripdl.\n",
      "[8/8] 2021-05-25 10:58:39\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 429 Tweets from @BerniniAM.\n",
      "\n",
      "FdI: ['GiorgiaMeloni', 'GuidoCrosetto', 'DSantanche']\n",
      "[1/3] 2021-05-25 10:58:44\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1548 Tweets from @GiorgiaMeloni.\n",
      "[2/3] 2021-05-25 10:59:02\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 8276 Tweets from @GuidoCrosetto.\n",
      "[3/3] 2021-05-25 11:00:18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1482 Tweets from @DSantanche.\n",
      "\n",
      "IV: ['ItaliaViva', 'matteorenzi', 'meb', 'Ettore_Rosato', 'TeresaBellanova', 'elenabonetti', 'davidefaraone']\n",
      "[1/7] 2021-05-25 11:00:36\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 3848 Tweets from @ItaliaViva.\n",
      "[2/7] 2021-05-25 11:01:15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 769 Tweets from @matteorenzi.\n",
      "[3/7] 2021-05-25 11:01:24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 196 Tweets from @meb.\n",
      "[4/7] 2021-05-25 11:01:27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 988 Tweets from @Ettore_Rosato.\n",
      "[5/7] 2021-05-25 11:01:40\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 1118 Tweets from @TeresaBellanova.\n",
      "[6/7] 2021-05-25 11:01:55\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 618 Tweets from @elenabonetti.\n",
      "[7/7] 2021-05-25 11:02:03\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[+] Finished: Successfully collected 244 Tweets from @davidefaraone.\n",
      "\n",
      "******************************\n",
      "  Start: 2021-05-25 10:53:46\n",
      "    End: 2021-05-25 11:02:06\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "tweets_df_list = {}\n",
    "\n",
    "for partito in partito_list:\n",
    "    username_list = partito_list[partito]\n",
    "    print(partito + \":\", username_list)\n",
    "    for i in range(len(username_list)):\n",
    "        user_name = username_list[i]\n",
    "        print(\"[\" + str(i+1) + \"/\" + str(len(username_list)) + \"]\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        try:\n",
    "            c = twint.Config()\n",
    "\n",
    "            c.Username = user_name\n",
    "            c.User_full = True         \n",
    "            c.Since = \"2020-06-03\"\n",
    "            c.Until = \"2021-05-15\"\n",
    "\n",
    "            c.Lowercase = True # rende tutto minuscolo\n",
    "\n",
    "            c.Count = True     # stampo a video il numero di tweet trovati\n",
    "            c.Pandas = True\n",
    "            c.Hide_output = True \n",
    "\n",
    "            twint.run.Search(c)\n",
    "\n",
    "            tweets_df_list[user_name] = twint.storage.panda.Tweets_df\n",
    "            tweets_df_list[user_name][\"partito\"] = partito\n",
    "        except Exception as ex:\n",
    "            print(\"*\"*30)\n",
    "            print(str(ex))\n",
    "            print(\"*\"*30)\n",
    "    print(\"\")\n",
    "\n",
    "print(\"\" + \"*\"*30)\n",
    "print(\"  Start:\", start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"    End:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unisco i vari dataframe contenuti nella lista `tweet_df_list` in uno unico che andr√† a formare il *corpus*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mov5Stelle          (1807, 39)\n",
      "luigidimaio          (436, 39)\n",
      "Roberto_Fico         (178, 39)\n",
      "LauraBottici          (93, 39)\n",
      "vitocrimi            (131, 39)\n",
      "virginiaraggi       (1018, 39)\n",
      "matteosalvinimi     (7328, 39)\n",
      "Fontana3Lorenzo     (1067, 39)\n",
      "massimogara          (975, 39)\n",
      "pdnetwork           (1185, 39)\n",
      "EnricoLetta         (1043, 39)\n",
      "itinagli             (405, 39)\n",
      "peppeprovenzano      (278, 39)\n",
      "F_Boccia             (150, 39)\n",
      "lauraboldrini        (420, 39)\n",
      "PaoloGentiloni       (369, 39)\n",
      "robersperanza        (181, 39)\n",
      "dariofrance           (85, 39)\n",
      "nzingaretti          (485, 39)\n",
      "ZanAlessandro        (149, 39)\n",
      "forza_italia         (621, 39)\n",
      "berlusconi           (616, 39)\n",
      "Antonio_Tajani      (1240, 39)\n",
      "msgelmini            (690, 39)\n",
      "mara_carfagna        (542, 39)\n",
      "renatobrunetta      (1429, 39)\n",
      "gasparripdl         (1358, 39)\n",
      "BerniniAM            (429, 39)\n",
      "GiorgiaMeloni       (1548, 39)\n",
      "GuidoCrosetto       (8276, 39)\n",
      "DSantanche          (1482, 39)\n",
      "ItaliaViva          (3848, 39)\n",
      "matteorenzi          (769, 39)\n",
      "meb                  (196, 39)\n",
      "Ettore_Rosato        (988, 39)\n",
      "TeresaBellanova     (1118, 39)\n",
      "elenabonetti         (618, 39)\n",
      "davidefaraone        (244, 39)\n",
      "------------------------------\n",
      "                   (43795, 39)\n"
     ]
    }
   ],
   "source": [
    "for user_name in tweets_df_list:\n",
    "    print(user_name.ljust(16), str(tweets_df_list[user_name].shape).rjust(13))\n",
    "print(\"-\"*30)\n",
    "\n",
    "# creo un unico dataframe\n",
    "tweets = pd.concat(tweets_df_list.values())\n",
    "print(\"\".ljust(16), str(tweets.shape).rjust(13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esporto il dataset originale in formato *csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets.to_csv(\"data/tweets_original_\"+datetime.now().strftime(\"%Y_%m_%d\")+\".csv\", sep=\"\\t\", index=False, encoding='utf-8-sig', mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gestisco gli emoji convertendoli in stringhe di testo comprensibile. Come deliminatore si utilizza `(\" emote_\",\" \")` in modo da rendere le emoji facilmente distinguibili; gli spazi servono per essere sicuri di considerarle come una singola entit√†."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"tweet\"] = tweets[\"tweet\"].apply(lambda x: demojize(x, language=\"en\", delimiters=(\" emote_\",\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infine, esporto il dataset normalizzato in formato *csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv(\"data/00_tweets.csv\", sep=\"\\t\", index=False, encoding='utf-8-sig', mode=\"w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "twitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
